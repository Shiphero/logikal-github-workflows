name: Run Python tests
on:
  workflow_call:
    inputs:
      python-version:
        description: The Python version to use
        type: number
        required: false
        default: 3.8
      requirements:
        description: The path to the requirements file
        type: string
        required: false
        default: requirements/dev.txt
      chrome-version:
        description: The Chrome and ChromeDriver version to install
        type: string
        required: false
      hadoop-version:
        description: The Hadoop version to install
        type: string
        required: false
      hadoop-gcs-connector-version:
        description: The Hadoop Google Cloud Storage connector version to install
        type: string
        required: false
      hadoop-aws-module-version:
        description: The Hadoop AWS module version to install
        type: string
        required: false

    secrets:
      TESTING_WORKLOAD_IDENTITY_PROVIDER:
        description: Full identifier of the GitHub workload identity pool provider in Google Cloud
        required: false
      TESTING_SERVICE_ACCOUNT:
        description: Email of the Google Cloud service account used for running tests
        required: false

concurrency:
  group: ${{ github.workflow }}-python-${{ github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  run-tests:
    name: Run tests
    runs-on: ubuntu-20.04
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v3
      - uses: google-github-actions/auth@v1
        env:
          RUN_STEP: ${{ secrets.TESTING_SERVICE_ACCOUNT != '' }}
        if: env.RUN_STEP == 'true'
        with:
          workload_identity_provider: ${{ secrets.TESTING_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.TESTING_SERVICE_ACCOUNT }}

      - uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python-version }}

      - uses: logikal-io/make-orb@v1.0.0
        with:
          requirements: ${{ inputs.requirements }}

      - uses: logikal-io/install-chrome@v1.0.0
        if: inputs.chrome-version != ''
        with:
          version: ${{ inputs.chrome-version }}

      - name: Install Hadoop
        if: inputs.hadoop-version != ''
        run: |-
          # Install Hadoop
          ENDPOINT='https://downloads.apache.org/hadoop/common/hadoop'
          VERSION='${{ inputs.hadoop-version }}'
          echo "Installing Hadoop ${VERSION}"
          wget "${ENDPOINT}-${VERSION}/hadoop-${VERSION}.tar.gz" \
            --progress=dot:giga -O /tmp/hadoop.tar.gz
          sudo tar -xzf /tmp/hadoop.tar.gz --directory /opt/
          sudo mv "/opt/hadoop-${VERSION}" /opt/hadoop
          rm /tmp/hadoop.tar.gz

          # Install Google Cloud Storage connector
          ENDPOINT='https://storage.googleapis.com/hadoop-lib/gcs'
          VERSION='${{ inputs.hadoop-gcs-connector-version }}'
          echo "Installing Google Cloud Storage connetor ${VERSION}"
          sudo wget "${ENDPOINT}/gcs-connector-hadoop3-${VERSION}.jar" --progress=dot:giga \
            -O "/opt/hadoop/share/hadoop/common/lib/gcs-connector-hadoop3-${VERSION}.jar"

          # Install AWS module
          echo "${SPARK_LOCAL_IP}"
          echo "${HADOOP_HOME}"
          echo "${HADOOP_COMMON_LIBS_JAR_DIR}"
          echo "${LD_LIBRARY_PATH}"

          # Set environment variables
          echo "HADOOP_HOME='/opt/hadoop'" >> $GITHUB_ENV
          echo "HADOOP_COMMON_LIBS_JAR_DIR='/opt/hadoop/share/hadoop/common/lib'" >> $GITHUB_ENV

          # export JAVA_HOME='/usr/lib/jvm/java-11-openjdk-amd64/'  # required by PySpark
          # export SPARK_LOCAL_IP='localhost'
          # export LD_LIBRARY_PATH="${LD_LIBRARY_PATH:+${LD_LIBRARY_PATH}:}${HADOOP_HOME}/lib/native"

      - name: Run pytest
        run: orb --command pytest

      - name: Upload pytest artifacts
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: pytest-artifacts
          path: /tmp/pytest-of-runner/
          if-no-files-found: ignore
          retention-days: 7
